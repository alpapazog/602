{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 4.16 (logistic regression only)\n",
        "---\n",
        "\n",
        "I am running a logistic regression model using sklearn. First I will split the data into training and test sets for model evaluation. I will also be using StandardScaler to standardize the features before applying the logisctic regression model.\n",
        "\n",
        "I am going to use the entire set of features at first and then I will train and test the model with three different subsets.\n",
        "\n",
        "You can skip to the end of this page to see the summary and interpertation of my results."
      ],
      "metadata": {
        "id": "FXqr4gSweFGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
      ],
      "metadata": {
        "id": "pzdqJuE-eLWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('Boston.csv')\n",
        "crim_median = df['crim'].median();\n",
        "df['high_crime'] = (df['crim'] > crim_median).astype(int)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRWCsJuxegDS",
        "outputId": "ae167195-2f4c-45ab-878a-9b9fe06ea5db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0     crim    zn  indus  chas    nox     rm   age     dis  rad  \\\n",
            "0           1  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1   \n",
            "1           2  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2   \n",
            "2           3  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2   \n",
            "3           4  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3   \n",
            "4           5  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3   \n",
            "\n",
            "   tax  ptratio  lstat  medv  high_crime  \n",
            "0  296     15.3   4.98  24.0           0  \n",
            "1  242     17.8   9.14  21.6           0  \n",
            "2  242     17.8   4.03  34.7           0  \n",
            "3  222     18.7   2.94  33.4           0  \n",
            "4  222     18.7   5.33  36.2           0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns=['Unnamed: 0', 'crim', 'high_crime'])\n",
        "y = df['high_crime']"
      ],
      "metadata": {
        "id": "Iv0lADQMggUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=9)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "k_fX9afTgWph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgoCJp5_hEAj",
        "outputId": "1d0b7e5b-1eb6-42f4-9bc7-6b7fa4a0a1c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.875\n",
            "[[74  6]\n",
            " [13 59]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.93      0.89        80\n",
            "           1       0.91      0.82      0.86        72\n",
            "\n",
            "    accuracy                           0.88       152\n",
            "   macro avg       0.88      0.87      0.87       152\n",
            "weighted avg       0.88      0.88      0.87       152\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subset_1 = ['rm', 'age', 'tax']\n",
        "X_train_subset1 = X_train[subset_1]\n",
        "X_test_subset1 = X_test[subset_1]\n",
        "\n",
        "# Scale subset features\n",
        "X_train_scaled_1 = scaler.fit_transform(X_train_subset1)\n",
        "X_test_scaled_1 = scaler.transform(X_test_subset1)\n",
        "\n",
        "# Fit logistic regression\n",
        "model.fit(X_train_scaled_1, y_train)\n",
        "y_pred_1 = model.predict(X_test_scaled_1)\n",
        "\n",
        "# Evaluate performance\n",
        "print(\"Subset 1 Accuracy:\", accuracy_score(y_test, y_pred_1))\n",
        "print(confusion_matrix(y_test, y_pred_1))\n",
        "print(classification_report(y_test, y_pred_1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zU0FQFAhUfj",
        "outputId": "c3e9611d-9eea-4b98-f0d5-d0d474227271"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subset 1 Accuracy: 0.8421052631578947\n",
            "[[71  9]\n",
            " [15 57]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.89      0.86        80\n",
            "           1       0.86      0.79      0.83        72\n",
            "\n",
            "    accuracy                           0.84       152\n",
            "   macro avg       0.84      0.84      0.84       152\n",
            "weighted avg       0.84      0.84      0.84       152\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subset_2 = ['indus', 'nox', 'ptratio', 'tax']\n",
        "X_train_subset2 = X_train[subset_2]\n",
        "X_test_subset2 = X_test[subset_2]\n",
        "\n",
        "# Scale subset features\n",
        "X_train_scaled_2 = scaler.fit_transform(X_train_subset2)\n",
        "X_test_scaled_2 = scaler.transform(X_test_subset2)\n",
        "\n",
        "# Fit logistic regression\n",
        "model.fit(X_train_scaled_2, y_train)\n",
        "y_pred_2 = model.predict(X_test_scaled_2)\n",
        "\n",
        "# Evaluate performance\n",
        "print(\"Subset 2 Accuracy:\", accuracy_score(y_test, y_pred_2))\n",
        "print(confusion_matrix(y_test, y_pred_2))\n",
        "print(classification_report(y_test, y_pred_2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0CQFkrAl936",
        "outputId": "9b7290a3-5a77-4640-a063-e46751990029"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subset 2 Accuracy: 0.8947368421052632\n",
            "[[75  5]\n",
            " [11 61]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.94      0.90        80\n",
            "           1       0.92      0.85      0.88        72\n",
            "\n",
            "    accuracy                           0.89       152\n",
            "   macro avg       0.90      0.89      0.89       152\n",
            "weighted avg       0.90      0.89      0.89       152\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subset_3 = ['dis', 'rad', 'medv', 'zn']\n",
        "X_train_subset3 = X_train[subset_3]\n",
        "X_test_subset3 = X_test[subset_3]\n",
        "\n",
        "# Scale subset features\n",
        "X_train_scaled_3 = scaler.fit_transform(X_train_subset3)\n",
        "X_test_scaled_3 = scaler.transform(X_test_subset3)\n",
        "\n",
        "# Fit logistic regression\n",
        "model.fit(X_train_scaled_3, y_train)\n",
        "y_pred_3 = model.predict(X_test_scaled_3)\n",
        "\n",
        "# Evaluate performance\n",
        "print(\"Subset 3 Accuracy:\", accuracy_score(y_test, y_pred_3))\n",
        "print(confusion_matrix(y_test, y_pred_3))\n",
        "print(classification_report(y_test, y_pred_3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bb2ojFYmmsnw",
        "outputId": "7d9a36c9-e7d7-4c56-8c16-a1d6bf5a03cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subset 3 Accuracy: 0.8223684210526315\n",
            "[[67 13]\n",
            " [14 58]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.84      0.83        80\n",
            "           1       0.82      0.81      0.81        72\n",
            "\n",
            "    accuracy                           0.82       152\n",
            "   macro avg       0.82      0.82      0.82       152\n",
            "weighted avg       0.82      0.82      0.82       152\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Results\n",
        "---\n",
        "### Original set (all features)\n",
        "Confusion Matrix\n",
        "\n",
        "|            | Predicted 0 | Predicted 1 |\n",
        "|------------|-------------|-------------|\n",
        "| Actual 0   | 74          | 6           |\n",
        "| Actual 1   | 13          | 59          |\n",
        "\n",
        "Classification Report\n",
        "\n",
        "| Class      | Precision | Recall | F1-Score | Support |\n",
        "|------------|-----------|--------|----------|---------|\n",
        "| 0          | 0.85      | 0.93   | 0.89     | 80      |\n",
        "| 1          | 0.91      | 0.82   | 0.86     | 72      |\n",
        "| **Accuracy**   |        |        | 0.88     | 152     |\n",
        "| **Macro Avg**  | 0.88   | 0.87   | 0.87     | 152     |\n",
        "| **Weighted Avg** | 0.88   | 0.88   | 0.87   | 152     |\n",
        "\n",
        "\n",
        "### Subset 1 (features: rm, age, tax)\n",
        "\n",
        "Confusion Matrix\n",
        "\n",
        "|            | Predicted 0 | Predicted 1 |\n",
        "|------------|-------------|-------------|\n",
        "| Actual 0   | 71          | 9           |\n",
        "| Actual 1   | 15          | 57          |\n",
        "\n",
        "Classification Report\n",
        "\n",
        "| Class      | Precision | Recall | F1-Score | Support |\n",
        "|------------|-----------|--------|----------|---------|\n",
        "| 0          | 0.83      | 0.89   | 0.86     | 80      |\n",
        "| 1          | 0.86      | 0.79   | 0.83     | 72      |\n",
        "| **Accuracy**   |        |        | 0.84     | 152     |\n",
        "| **Macro Avg**  | 0.84   | 0.84   | 0.84     | 152     |\n",
        "| **Weighted Avg** | 0.84   | 0.84   | 0.84   | 152     |\n",
        "\n",
        "### Subset 2 (features: indus, nox, ptratio, tax)\n",
        "\n",
        "Confusion Matrix\n",
        "\n",
        "|            | Predicted 0 | Predicted 1 |\n",
        "|------------|-------------|-------------|\n",
        "| Actual 0   | 75          | 5           |\n",
        "| Actual 1   | 11          | 61          |\n",
        "\n",
        "Classification Report\n",
        "\n",
        "| Class      | Precision | Recall | F1-Score | Support |\n",
        "|------------|-----------|--------|----------|---------|\n",
        "| 0          | 0.87      | 0.94   | 0.90     | 80      |\n",
        "| 1          | 0.92      | 0.85   | 0.88     | 72      |\n",
        "| **Accuracy**   |        |        | 0.89     | 152     |\n",
        "| **Macro Avg**  | 0.90   | 0.89   | 0.89     | 152     |\n",
        "| **Weighted Avg** | 0.90 | 0.89   | 0.89     | 152     |\n",
        "\n",
        "\n",
        "### Subset 3 (features: dis, rad, medv, zn)\n",
        "Confusion Matrix\n",
        "\n",
        "|            | Predicted 0 | Predicted 1 |\n",
        "|------------|-------------|-------------|\n",
        "| Actual 0   | 67          | 13          |\n",
        "| Actual 1   | 14          | 58          |\n",
        "\n",
        "Classification Report\n",
        "\n",
        "| Class      | Precision | Recall | F1-Score | Support |\n",
        "|------------|-----------|--------|----------|---------|\n",
        "| 0          | 0.83      | 0.84   | 0.83     | 80      |\n",
        "| 1          | 0.82      | 0.81   | 0.81     | 72      |\n",
        "| **Accuracy**   |        |        | 0.82     | 152     |\n",
        "| **Macro Avg**  | 0.82   | 0.82   | 0.82     | 152     |\n",
        "| **Weighted Avg** | 0.82   | 0.82   | 0.82   | 152     |\n",
        "\n",
        "\n",
        "\n",
        "### Results summary\n",
        "| Model Set   | Accuracy | Precision (0) | Recall (0) | F1-Score (0) | Precision (1) | Recall (1) | F1-Score (1) |\n",
        "|-------------|----------|---------------|------------|--------------|---------------|------------|--------------|\n",
        "| Original    | 0.875    | 0.85          | 0.93       | 0.89         | 0.91          | 0.82       | 0.86         |\n",
        "| Subset 1    | 0.8421   | 0.83          | 0.89       | 0.86         | 0.86          | 0.79       | 0.83         |\n",
        "| Subset 2    | **0.8947**| 0.87          | **0.94**   | **0.90**     | **0.92**      | 0.85       | **0.88**     |\n",
        "| Subset 3    | 0.8224   | 0.83          | 0.84       | 0.83         | 0.82          | 0.81       | 0.81         |\n",
        "\n"
      ],
      "metadata": {
        "id": "5ys0OaQxnQda"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Subset 2 has the highest accuracy (0.8947), with excellent precision, recall, and F1-scores, particularly for class 1 (above-median crime rate).\n",
        "*   Original Set performs quite well with a solid accuracy of 0.875 and balanced F1-scores for both classes.\n",
        "*   Subset 1 has slightly lower performance compared to the original set, particularly in recall for class 1, which dropped to 0.79.\n",
        "*   Subset 3 shows the lowest accuracy (0.8224) and slightly weaker performance in both precision and recall for both classes.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Subset 2's strong performance (accuracy of 0.8947) suggests that  environmental (nox) and socio-economic factors (indus, ptratio, tax) provide valuable information for classifying crime rates"
      ],
      "metadata": {
        "id": "kOuFKokAPByN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " New Section"
      ],
      "metadata": {
        "id": "WhpriIQGXrqC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 6.11 (for LASSO and ridge only)\n",
        "---"
      ],
      "metadata": {
        "id": "tAFlKvA1XwqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ],
      "metadata": {
        "id": "slwbQdIWYRiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Boston dataset\n",
        "df = pd.read_csv('Boston.csv')\n",
        "X = df.drop(columns=['Unnamed: 0', 'crim'])\n",
        "y = df['crim']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
        "\n",
        "# Standardize the data (important for Lasso)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "bXl0xCJRYSX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LASSO**\n",
        "\n"
      ],
      "metadata": {
        "id": "2pQxmOHqZ3QI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lasso = Lasso(alpha=0.1)\n",
        "lasso.fit(X_train_scaled, y_train)\n",
        "y_pred = lasso.predict(X_test_scaled)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(\"Lasso Coefficients:\", lasso.coef_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEIfCu-iZJZb",
        "outputId": "bf63a3d6-926f-4198-f8e1-661e933a8d2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 47.31442490271197\n",
            "Lasso Coefficients: [ 0.68552554 -0.         -0.22260961 -0.62485611  0.14489728  0.10394735\n",
            " -1.41375269  4.50887328  0.         -0.36020619  0.07751059 -1.59727234]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ridge**"
      ],
      "metadata": {
        "id": "9rGe__iSaDgb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ridge = Ridge(alpha=1.0)\n",
        "ridge.fit(X_train_scaled, y_train)\n",
        "y_pred = ridge.predict(X_test_scaled)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(\"Ridge Coefficients:\", ridge.coef_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jduChRRVaHQk",
        "outputId": "4e2c02d0-aa50-451b-8fff-4159c1f049b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 46.72695922739183\n",
            "Ridge Coefficients: [ 0.98599621 -0.00601307 -0.28694681 -1.47310971  0.40794745  0.35019343\n",
            " -2.07855074  5.13433673 -0.39439014 -0.7171805   0.1435563  -2.124527  ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results for both Ridge and Lasso regression show similar performance in terms of Mean Squared Error:\n",
        "\n",
        "Lasso Regression MSE: 47.31\n",
        "Ridge Regression MSE: 46.73\n",
        "The MSE values are quite close, indicating that both models are performing similarly for predicting the per capita crime rate in the dataset.\n",
        "\n",
        "Lasso Regression: Some coefficients are set to zero, which means certain features are effectively removed from the model. From the coefficients output, features 'zn' and 'rad' have been set to zero, indicating that Lasso did some feature selection. The slightly higher MSE may be due to the removal of some useful predictors, but it also simplifies the model by reducing the number of\n",
        "  active variables.\n",
        "\n",
        "Ridge Regression: This model retains all features and shrinks the coefficients to reduce overfitting, which can explain its slightly lower MSE compared to Lasso. Ridge doesn't perform feature selection but can handle correlated predictors better.\n",
        "\n",
        "The MSE in both regression models is pretty high indicating that some optimization and tuning would be required in order to obtain more effective regression models.\n"
      ],
      "metadata": {
        "id": "pybw7HyjuqD3"
      }
    }
  ]
}